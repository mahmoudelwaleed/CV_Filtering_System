{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3058dd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true 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 https://api.smith.langchain.com CV_Filter\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "tracing = os.environ.get(\"LANGSMITH_TRACING\")\n",
    "api_key = os.environ.get(\"LANGSMITH_API_KEY\")\n",
    "endpoint = os.environ.get(\"LANGSMITH_ENDPOINT\")\n",
    "project = os.environ.get(\"LANGSMITH_PROJECT\")\n",
    "\n",
    "print(tracing, api_key, endpoint, project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85247456",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"CV_Filter\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a1520e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import utils\n",
    "utils.tracing_is_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42205e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "# === SECTION PARSING UTILITIES ===\n",
    "SECTION_KEYWORDS = {\n",
    "    \"summary\": r\"^\\s*(summary|profile|objective|about me|professional summary)\\s*:?\\s*$\",\n",
    "    \"experience\": r\"^\\s*(experience|work history|employment|professional experience)\\s*:?\\s*$\",\n",
    "    \"education\": r\"^\\s*(education|academic background|qualifications)\\s*:?\\s*$\",\n",
    "    \"skills\": r\"^\\s*(skills|technical skills|competencies|proficiencies|technical expertise)\\s*:?\\s*$\",\n",
    "    \"certifications\": r\"^\\s*(certifications|licenses|courses|training)\\s*:?\\s*$\",\n",
    "    \"projects\": r\"^\\s*(projects|personal projects|key projects)\\s*:?\\s*$\",\n",
    "    \"languages\": r\"^\\s*(languages)\\s*:?\\s*$\",\n",
    "}\n",
    "\n",
    "DEFAULT_SECTION = \"header\"\n",
    "LIST_SECTIONS = [\"experience\", \"education\", \"certifications\", \"projects\"]\n",
    "\n",
    "def identify_section(line):\n",
    "    for section, pattern in SECTION_KEYWORDS.items():\n",
    "        if re.match(pattern, line, re.IGNORECASE):\n",
    "            return section\n",
    "    return None\n",
    "\n",
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    lines = [line.strip() for line in text.strip().split('\\n')]\n",
    "    return \"\\n\".join([line for line in lines if line])\n",
    "\n",
    "def naive_split_entries(text_block):\n",
    "    if not text_block:\n",
    "        return []\n",
    "    entries = re.split(r'\\n\\s*\\n+', text_block.strip())\n",
    "    return [entry.strip() for entry in entries if entry.strip()]\n",
    "\n",
    "def chunk_text_into_sections(text):\n",
    "    lines = text.split('\\n')\n",
    "    sections_content = defaultdict(str)\n",
    "    current_section = DEFAULT_SECTION\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        matched_section = identify_section(stripped)\n",
    "        if matched_section:\n",
    "            current_section = matched_section\n",
    "            continue\n",
    "        sections_content[current_section] += line + \"\\n\"\n",
    "\n",
    "    chunked_sections = {}\n",
    "    for section_name, content in sections_content.items():\n",
    "        if section_name in LIST_SECTIONS:\n",
    "            chunked_sections[section_name] = naive_split_entries(clean_text(content))\n",
    "        else:\n",
    "            chunked_sections[section_name] = clean_text(content)\n",
    "\n",
    "    return chunked_sections\n",
    "\n",
    "# === LOADER SETUP WITH LANGCHAIN ===\n",
    "def pdf_loader_single(file_path):\n",
    "    return PyPDFLoader(file_path, mode=\"single\")\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    r\"D:\\GBG\\tasks\\langchain\\last\\cv_pdfs\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls=pdf_loader_single\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} documents\")\n",
    "\n",
    "# === PROCESS DOCUMENT TEXTS ===\n",
    "structured_docs = []\n",
    "for doc in docs:\n",
    "    text = doc.page_content\n",
    "    pdf_path = doc.metadata[\"source\"]\n",
    "    structured = chunk_text_into_sections(text)\n",
    "    structured_docs.append({\n",
    "        \"file\": pdf_path,\n",
    "        \"sections\": structured\n",
    "    })\n",
    "\n",
    "# === DISPLAY OUTPUT ===\n",
    "for doc in structured_docs:\n",
    "    print(f\"\\nFile: {doc['file']}\")\n",
    "    for section, content in doc[\"sections\"].items():\n",
    "        print(f\"\\n== {section.upper()} ==\")\n",
    "        if isinstance(content, list):\n",
    "            for entry in content:\n",
    "                print(f\"- {entry}\")\n",
    "        else:\n",
    "            print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings ,AzureChatOpenAI\n",
    "#Embedding_Model\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    azure_endpoint=\"\",\n",
    "    api_key=\"\",\n",
    "    openai_api_version=\"2023-05-15\",\n",
    ")\n",
    "\n",
    "#Chat Model\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    "    azure_endpoint=\"\",\n",
    "    api_key=\"\",\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0cbd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 9, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_7a53abb7a2', 'id': 'chatcmpl-BVGmkpfR5f2IPuJEtMUScuyzw5m2M', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run--4c465f09-2309-4e65-a2a6-d689dd269cec-0', usage_metadata={'input_tokens': 9, 'output_tokens': 10, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm.invoke(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca1c0379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qdrant-client[fastembed] in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (1.12.2)\n",
      "Collecting fastembed==0.5.0 (from qdrant-client[fastembed])\n",
      "  Downloading fastembed-0.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from qdrant-client[fastembed]) (1.67.1)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from qdrant-client[fastembed]) (1.67.1)\n",
      "Requirement already satisfied: httpx>=0.20.0 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client[fastembed]) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.26 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from qdrant-client[fastembed]) (1.26.4)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from qdrant-client[fastembed]) (2.10.1)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from qdrant-client[fastembed]) (2.10.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from qdrant-client[fastembed]) (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from fastembed==0.5.0->qdrant-client[fastembed]) (0.30.2)\n",
      "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from fastembed==0.5.0->qdrant-client[fastembed]) (0.7.3)\n",
      "Collecting mmh3<5.0.0,>=4.1.0 (from fastembed==0.5.0->qdrant-client[fastembed])\n",
      "  Downloading mmh3-4.1.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting onnx>=1.15.0 (from fastembed==0.5.0->qdrant-client[fastembed])\n",
      "  Downloading onnx-1.17.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: onnxruntime!=1.20.0,>=1.17.0 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from fastembed==0.5.0->qdrant-client[fastembed]) (1.20.1)\n",
      "Collecting pillow<11.0.0,>=10.3.0 (from fastembed==0.5.0->qdrant-client[fastembed])\n",
      "  Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed==0.5.0->qdrant-client[fastembed])\n",
      "  Downloading py_rust_stemmers-0.1.5-cp312-none-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from fastembed==0.5.0->qdrant-client[fastembed]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from fastembed==0.5.0->qdrant-client[fastembed]) (0.21.1)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from fastembed==0.5.0->qdrant-client[fastembed]) (4.67.1)\n",
      "Requirement already satisfied: filelock in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from huggingface-hub<1.0,>=0.20->fastembed==0.5.0->qdrant-client[fastembed]) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from huggingface-hub<1.0,>=0.20->fastembed==0.5.0->qdrant-client[fastembed]) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from huggingface-hub<1.0,>=0.20->fastembed==0.5.0->qdrant-client[fastembed]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from huggingface-hub<1.0,>=0.20->fastembed==0.5.0->qdrant-client[fastembed]) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from huggingface-hub<1.0,>=0.20->fastembed==0.5.0->qdrant-client[fastembed]) (4.13.2)\n",
      "Requirement already satisfied: colorama>=0.3.4 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from loguru<0.8.0,>=0.7.2->fastembed==0.5.0->qdrant-client[fastembed]) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from loguru<0.8.0,>=0.7.2->fastembed==0.5.0->qdrant-client[fastembed]) (1.2.0)\n",
      "Requirement already satisfied: pywin32>=226 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client[fastembed]) (310)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from requests<3.0,>=2.31->fastembed==0.5.0->qdrant-client[fastembed]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from requests<3.0,>=2.31->fastembed==0.5.0->qdrant-client[fastembed]) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from requests<3.0,>=2.31->fastembed==0.5.0->qdrant-client[fastembed]) (2025.4.26)\n",
      "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client[fastembed]) (5.29.4)\n",
      "Requirement already satisfied: setuptools in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client[fastembed]) (80.3.1)\n",
      "Requirement already satisfied: anyio in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client[fastembed]) (4.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (4.1.0)\n",
      "Requirement already satisfied: coloredlogs in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed==0.5.0->qdrant-client[fastembed]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed==0.5.0->qdrant-client[fastembed]) (25.2.10)\n",
      "Requirement already satisfied: sympy in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed==0.5.0->qdrant-client[fastembed]) (1.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client[fastembed]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client[fastembed]) (2.27.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed==0.5.0->qdrant-client[fastembed]) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed==0.5.0->qdrant-client[fastembed]) (3.5.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\gbg\\tasks\\langchain\\lang\\lib\\site-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed==0.5.0->qdrant-client[fastembed]) (1.3.0)\n",
      "Downloading fastembed-0.5.0-py3-none-any.whl (69 kB)\n",
      "Downloading mmh3-4.1.0-cp312-cp312-win_amd64.whl (31 kB)\n",
      "Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.6 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.3/2.6 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.1/2.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading py_rust_stemmers-0.1.5-cp312-none-win_amd64.whl (209 kB)\n",
      "Downloading onnx-1.17.0-cp312-cp312-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/14.5 MB 3.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.6/14.5 MB 3.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.4/14.5 MB 3.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.1/14.5 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.7/14.5 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.9/14.5 MB 3.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 5.2/14.5 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.8/14.5 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.8/14.5 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.6/14.5 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.4/14.5 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.9/14.5 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.7/14.5 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.5/14.5 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.3/14.5 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.1/14.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.8/14.5 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.5 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.5 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.9/14.5 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.9/14.5 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.5 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 2.6 MB/s eta 0:00:00\n",
      "Installing collected packages: py-rust-stemmers, mmh3, pillow, onnx, fastembed\n",
      "\n",
      "  Attempting uninstall: mmh3\n",
      "\n",
      "    Found existing installation: mmh3 5.1.0\n",
      "\n",
      "    Uninstalling mmh3-5.1.0:\n",
      "\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "      Successfully uninstalled mmh3-5.1.0\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "  Attempting uninstall: pillow\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "    Found existing installation: pillow 11.1.0\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "    Uninstalling pillow-11.1.0:\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "   -------- ------------------------------- 1/5 [mmh3]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ---------------- ----------------------- 2/5 [pillow]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   ------------------------ --------------- 3/5 [onnx]\n",
      "   -------------------------------- ------- 4/5 [fastembed]\n",
      "   -------------------------------- ------- 4/5 [fastembed]\n",
      "   -------------------------------- ------- 4/5 [fastembed]\n",
      "   ---------------------------------------- 5/5 [fastembed]\n",
      "\n",
      "Successfully installed fastembed-0.5.0 mmh3-4.1.0 onnx-1.17.0 pillow-10.4.0 py-rust-stemmers-0.1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\GBG\\tasks\\langchain\\lang\\Lib\\site-packages\\~il'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "open-webui 0.6.6 requires fastapi==0.115.7, but you have fastapi 0.115.12 which is incompatible.\n",
      "open-webui 0.6.6 requires pillow==11.1.0, but you have pillow 10.4.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "##Qdrant db\n",
    "!pip install qdrant-client[fastembed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17996391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GBG\\tasks\\langchain\\lang\\Lib\\site-packages\\PIL\\Image.py:122: RuntimeWarning: The _imaging extension was built for another version of Pillow or PIL:\n",
      "Core version: 10.4.0\n",
      "Pillow version: 11.1.0\n",
      "  warnings.warn(str(v), RuntimeWarning)\n",
      "d:\\GBG\\tasks\\langchain\\lang\\Lib\\site-packages\\PIL\\Image.py:122: RuntimeWarning: The _imaging extension was built for another version of Pillow or PIL:\n",
      "Core version: 10.4.0\n",
      "Pillow version: 11.1.0\n",
      "  warnings.warn(str(v), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Qdrant\n",
    "import qdrant_client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5cc96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GBG\\tasks\\langchain\\lang\\Lib\\site-packages\\PIL\\Image.py:122: RuntimeWarning: The _imaging extension was built for another version of Pillow or PIL:\n",
      "Core version: 10.4.0\n",
      "Pillow version: 11.1.0\n",
      "  warnings.warn(str(v), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#qdrant client\n",
    "\n",
    "os.environ[\"qdrant_host\"] = \"\"\n",
    "os.environ[\"qdrant_api_key\"] = \"\"\n",
    "\n",
    "qdrant_client = qdrant_client.QdrantClient(\n",
    "    url=os.environ[\"qdrant_host\"],\n",
    "    api_key=os.environ[\"qdrant_api_key\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d809b4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create collection\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "os.environ[\"qdrant_collection_name\"] = \"my_collection\"\n",
    "\n",
    "vectors_config=models.VectorParams(size=1536,\n",
    "                                    distance=models.Distance.COSINE)\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=os.environ[\"qdrant_collection_name\"],\n",
    "    vectors_config=vectors_config,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64da0d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create vector store\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "vector_store = Qdrant(\n",
    "    client=qdrant_client,\n",
    "    collection_name=os.environ[\"qdrant_collection_name\"],\n",
    "    embeddings=embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31d3e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add documents to vector store\n",
    "from langchain_core.documents import Document\n",
    "from uuid import uuid4\n",
    "\n",
    "all_langchain_documents = []\n",
    "\n",
    "for s_doc in structured_docs:\n",
    "    doc_name = s_doc['file']\n",
    "    sections = s_doc['sections']\n",
    "\n",
    "    for chunk_type, content in sections.items():\n",
    "        if isinstance(content, list):\n",
    "            for item in content:\n",
    "                if item.strip(): \n",
    "                    all_langchain_documents.append(\n",
    "                        Document(\n",
    "                            page_content=item,\n",
    "                            metadata={\n",
    "                                \"doc_name\": doc_name,\n",
    "                                \"chunk_type\": chunk_type,\n",
    "                                \"chunk_id\": str(uuid4())\n",
    "                            }\n",
    "                        )\n",
    "                    )\n",
    "        elif isinstance(content, str):\n",
    "            if content.strip():\n",
    "                all_langchain_documents.append(\n",
    "                    Document(\n",
    "                        page_content=content,\n",
    "                        metadata={\n",
    "                            \"doc_name\": doc_name,\n",
    "                            \"chunk_type\": chunk_type,\n",
    "                            \"chunk_id\": str(uuid4())\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "if all_langchain_documents:\n",
    "    vector_store.add_documents(all_langchain_documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lang)",
   "language": "python",
   "name": "lang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
